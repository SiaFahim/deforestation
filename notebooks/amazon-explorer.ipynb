{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jpeg_data_files_paths():\n",
    "    \"\"\"\n",
    "    Returns the input file folders path\n",
    "    \n",
    "    :return: The input file paths as list [train_jpeg_dir, test_jpeg_dir, test_jpeg_additional, train_csv_file]\n",
    "    \"\"\"\n",
    "\n",
    "    data_root_folder = \"/root/input\"\n",
    "    train_jpeg_dir = os.path.join(data_root_folder, 'train-jpg')\n",
    "    test_jpeg_dir = os.path.join(data_root_folder, 'test-jpg')\n",
    "    test_jpeg_additional = os.path.join(data_root_folder, 'test-jpg-additional')\n",
    "    train_csv_file = os.path.join(data_root_folder, 'train_v2.csv')\n",
    "\n",
    "    assert os.path.exists(data_root_folder), \"The {} folder does not exist\".format(data_root_folder)\n",
    "    assert os.path.exists(train_jpeg_dir), \"The {} folder does not exist\".format(train_jpeg_dir)\n",
    "    assert os.path.exists(test_jpeg_dir), \"The {} folder does not exist\".format(test_jpeg_dir)\n",
    "    assert os.path.exists(train_csv_file), \"The {} file does not exist\".format(test_jpeg_additional)\n",
    "    assert os.path.exists(train_csv_file), \"The {} file does not exist\".format(train_csv_file)\n",
    "    return [train_jpeg_dir, test_jpeg_dir, test_jpeg_additional, train_csv_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_transform_to_matrices(*args):\n",
    "    file_path, tags, labels_map, img_resize = args[0][0], args[0][1], args[0][2], args[0][3]\n",
    "    img_array = np.array(cv2.resize(cv2.imread(file_path), img_resize), dtype=np.float32)\n",
    "    cv2.normalize(img_array, img_array, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    targets = np.zeros(len(labels_map))\n",
    "    for t in tags.split(' '):\n",
    "        targets[labels_map[t]] = 1\n",
    "    return img_array, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _test_transform_to_matrices(*args):\n",
    "    test_set_folder, file_name, img_resize = args[0][0], args[0][1], args[0][2]\n",
    "    img_array = np.array(cv2.resize(cv2.imread('{}/{}'.format(test_set_folder, file_name)), img_resize),\n",
    "                         dtype=np.float32)\n",
    "    cv2.normalize(img_array, img_array, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    return [img_array, file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_train_matrices(train_set_folder, train_csv_file, img_resize, process_count):\n",
    "    labels_df = pd.read_csv(train_csv_file)\n",
    "    labels = sorted(set(chain.from_iterable([tags.split(\" \") for tags in labels_df['tags'].values])))\n",
    "    labels_map = {l: i for i, l in enumerate(labels)}\n",
    "\n",
    "    files_path = []\n",
    "    tags_list = []\n",
    "    for file_name, tags in labels_df.values:\n",
    "        files_path.append('{}/{}.jpg'.format(train_set_folder, file_name))\n",
    "        tags_list.append(tags)\n",
    "\n",
    "    # Multiprocess transformation\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    print(\"Transforming train data to matrices. Using {} threads...\".format(process_count))\n",
    "    sys.stdout.flush()\n",
    "    with ThreadPoolExecutor(process_count) as pool:\n",
    "        for img_array, targets in tqdm(pool.map(_train_transform_to_matrices,\n",
    "                                                [[file_path, tag, labels_map, img_resize]\n",
    "                                                 for file_path, tag in zip(files_path, tags_list)]),\n",
    "                                       total=len(files_path)):\n",
    "            x_train.append(img_array)\n",
    "            y_train.append(targets)\n",
    "    return [x_train, y_train, {v: k for k, v in labels_map.items()}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_test_matrices(test_set_folder, img_resize, process_count):\n",
    "    x_test = []\n",
    "    x_test_filename = []\n",
    "    files_name = os.listdir(test_set_folder)\n",
    "\n",
    "    with ThreadPoolExecutor(process_count) as pool:\n",
    "        for img_array, file_name in tqdm(pool.map(_test_transform_to_matrices,\n",
    "                                             [[test_set_folder, file_name, img_resize]\n",
    "                                              for file_name in files_name]),\n",
    "                                         total=len(files_name)):\n",
    "            x_test.append(img_array)\n",
    "            x_test_filename.append(file_name)\n",
    "    return [x_test, x_test_filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_train_data(train_set_folder, train_csv_file, img_resize=(32, 32), process_count=cpu_count()):\n",
    "    \"\"\"\n",
    "    Transform the train images to ready to use data for the CNN \n",
    "    :param train_set_folder: the folder containing the images for training\n",
    "    :param train_csv_file: the file containing the labels of the training images\n",
    "    :param img_resize: the standard size you want to have on images when transformed to matrices\n",
    "    :param process_count: the number of process you want to use to preprocess the data.\n",
    "        If you run into issues, lower this number. Its default value is equal to the number of core of your CPU\n",
    "    :return: The images matrices and labels as [x_train, y_train, labels_map]\n",
    "        x_train: The X train values as a numpy array\n",
    "        y_train: The Y train values as a numpy array\n",
    "        labels_map: The mapping between the tags labels and their indices\n",
    "    \"\"\"\n",
    "    x_train, y_train, labels_map = _get_train_matrices(train_set_folder, train_csv_file, img_resize, process_count)\n",
    "    ret = [np.array(x_train), np.array(y_train, dtype=np.uint8), labels_map]\n",
    "    print(\"Done. Size consumed by arrays {} mb\".format((ret[0].nbytes + ret[1].nbytes) / 1024 / 1024))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_test_data(test_set_folder, img_resize=(32, 32), process_count=cpu_count()):\n",
    "    \"\"\"\n",
    "    Transform the images to ready to use data for the CNN\n",
    "    :param test_set_folder: the folder containing the images for testing\n",
    "    :param img_resize: the standard size you want to have on images when transformed to matrices\n",
    "    :param process_count: the number of process you want to use to preprocess the data.\n",
    "        If you run into issues, lower this number. Its default value is equal to the number of core of your CPU\n",
    "    :return: The images matrices and labels as [x_test, x_test_filename]\n",
    "        x_test: The X test values as a numpy array\n",
    "        x_test_filename: The files name of each test images in the same order as the x_test arrays\n",
    "    \"\"\"\n",
    "    x_test, x_test_filename = _get_test_matrices(test_set_folder, img_resize, process_count)\n",
    "    ret = [np.array(x_test), x_test_filename]\n",
    "    print(\"Done. Size consumed by arrays {} mb\".format(ret[0].nbytes / 1024 / 1024))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train_set_folder, test_set_folder,\n",
    "                    test_set_additional, train_csv_file, img_resize=(32, 32), process_count=cpu_count()):\n",
    "    \"\"\"\n",
    "    Transform the all the images to ready to use data for the CNN\n",
    "    :param train_set_folder: the folder containing the images for training\n",
    "    :param test_set_folder: the folder containing the images for testing\n",
    "    :param test_set_additional: the folder containing the images for additional testing (updated on 05/05/2017) \n",
    "            https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/32157\n",
    "    :param train_csv_file: the file containing the labels of the training images\n",
    "    :param img_resize: the standard size you want to have on images when transformed to matrices\n",
    "    :param process_count: the number of process you want to use to preprocess the data.\n",
    "        If you run into issues, lower this number. Its default value is equal to the number of core of your CPU\n",
    "    :return: The images matrices and labels as [x_train, x_test, y_train, labels_map, x_test_filename]\n",
    "        x_train: The X train values as a numpy array\n",
    "        x_test: The X test values as a numpy array\n",
    "        y_train: The Y train values as a numpy array\n",
    "        labels_map: The mapping between the tags labels and their indices\n",
    "        x_test_filename: The files name of each test images in the same order as the x_test arrays\n",
    "    \"\"\"\n",
    "    x_train, y_train, labels_map = _get_train_matrices(train_set_folder, train_csv_file, img_resize, process_count)\n",
    "    print(\"Transforming test data to matrices. Using {} threads...\".format(process_count))\n",
    "    sys.stdout.flush()\n",
    "    x_test, x_test_filename = _get_test_matrices(test_set_folder, img_resize, process_count)\n",
    "    print(\"Transforming additional test data to matrices. Using {} threads...\".format(process_count))\n",
    "    sys.stdout.flush()\n",
    "    x_test_add, x_test_filename_add = _get_test_matrices(test_set_additional, img_resize, process_count)\n",
    "    x_test = np.vstack((x_test, x_test_add))\n",
    "    x_test_filename = np.hstack((x_test_filename, x_test_filename_add))\n",
    "    ret = [np.array(x_train), np.array(x_test), np.array(y_train, dtype=np.uint8), labels_map, x_test_filename]\n",
    "    gc.collect()\n",
    "    print(\"Done. Size consumed by arrays {} mb\".format((ret[0].nbytes + ret[1].nbytes + ret[2].nbytes) /1024/1024))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
